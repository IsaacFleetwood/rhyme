% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}

\pagestyle{plain}
\usepackage{lineno}
\usepackage{hyperref} % to make refs clickable
\usepackage{xcolor}
\usepackage{listings}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{cite}
\usepackage{textcomp} % for having straight quotes ' in lstlisting
\usepackage{amsmath} % use align for grammar
\usepackage{cleveref}
\usepackage[scaled]{beramono} % nicer font for code snippets

\usepackage{wrapfig}


\input{macros.tex}

\linenumbers

% \newcommand{\lang}{\textcolor{blue}{QL-TBD}}
\newcommand{\lang}{Rhyme}

\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\begin{document}
%
\title{\lang{}: A Data-Centric Expressive Query Language for Nested Data Structures}

\author{}
\institute{}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
% \author{Supun Abeysinghe\inst{1}\orcidID{0000-1111-2222-3333} \and
% Tiark Rompf\inst{2,3}\orcidID{1111-2222-3333-4444}}
% \author{Supun Abeysinghe \and Tiark Rompf}
% %
% \authorrunning{F. Author et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
% \institute{Purdue University, West Lafayette IN 47906, USA\\
% \email{\{tabeysin,tiark\}@purdue.com}
% }
%
\maketitle              % typeset the header of the contribution
\vspace{-15mm} %TODO: remove
%
\begin{abstract}
We present \lang{},
% (stands for JSON query notation)
an expressive language
designed for high-level data manipulation, with a primary focus on querying
and transforming nested structures such as JSON and tensors,
while yielding nested structures as output.
\lang{} draws inspiration from a diverse range of declarative languages,
including Datalog, JQ, JSONiq, Einstein summation (Einsum), GraphQL, and more
recent functional logic programming languages like Verse.
It has a syntax that closely resembles existing object notation,
is compositional, and has the ability to perform query optimization and
code generation through the construction of an intermediate
representation (IR).
Our IR comprises loop-free and branch-free code with program structure
implicitly captured via dependencies.
To demonstrate \lang{}'s versatility, 
we implement \lang{} in JavaScript (as an embedded DSL) and 
illustrate its application
across various domains, showcasing its ability to express common
data manipulation queries, tensor expressions (Ã  la Einsum), and more.
% \keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%
\vspace{-10mm}
\section{Introduction}\label{sec:intro}
\vspace{-3mm}

Declarative programming represents a paradigm in which users articulate \emph{what}
computation needs to be performed, without the explicit specification of the
procedural steps required for its execution.
Declarative programming languages find application across a diverse array of
domains.
Notable examples include SQL, employed for data querying and manipulation,
Datalog~\cite{datalog}, used for data querying as well as in domains like
declarative program analysis~\cite{proganalysis_first, logic_proganalysis, souffle_cav}
and binary decompilation~\cite{ddissam}, Einstein notation (or similar domain
specific languages~\cite{tensor_comprehensions}) for expressing tensor computations
mathematically, and GraphQL~\cite{graphql} for data querying within the context of web application
front-ends, and so on.

In practical scenarios where diverse paradigms of workloads are combined
(e.g., data frames + tensors), the necessity arises to employ multiple
query languages in tandem.
Each of these languages interfaces with the respective engines tasked
with handling individual workloads.
However, this approach is inherently inefficient, both from a performance
perspective, due to the reliance on multiple isolated backends, and from
a programmer productivity standpoint, as it necessitates learning and
maintaining code written in multiple query languages.
In this work, we address this challenge by introducing a unified query language, 
named \lang{},
that comprises a general substrate capable of accommodating a wide array of
different use cases.

\lang{} takes inspiration from many existing declarative languages
including GraphQL, JQ~\cite{jq}, XQuery~\cite{xquery}, JSONPath~\cite{jsonpath}, Einstein notation,
Datalog, recent functional logic programming languages like Verse~\cite{verse}, etc.
\lang{} is designed to serve as an expressive language for high-level data
manipulation, enabling the querying and transformation of nested data structures
(e.g., JSON, tensors)
and producing nested structures as output.
There are several key defining characteristics of \lang{}.
First, \lang{} adopts a query syntax that closely mirrors existing object notation,
meaning that queries are essentially expressed as JSON objects.
Second, \lang{} is designed in a way that permits query optimization and
code generation via the construction of an intermediate representation (IR).
This IR contains loop-free and branch-free code with dependencies that implicitly
capture the program structure.
Third, \lang{} is compositional and easy to meta-program, recognizing that data
transformation queries are typically used as part of larger programs and are often
generated programmatically.

\begin{figure}[t!]
\centering
\includegraphics[width=0.8\textwidth]{images/intro_fig.pdf}
\caption{
End-to-end workflow of \lang{}, with green markers indicating various entry points
leading to the common entry point, \lang{} AST.
The \lang{} AST can be constructed directly from external tools or via metaprogramming
using different APIs.
This AST serves as the basis for generating an IR (with dependencies), driving
subsequent code generation.
}\label{fig:intro_overview}
\vspace{-7mm}
\end{figure}

\Cref{fig:intro_overview} provides an overview of the end-to-end workflow of \lang{}.
The central point of entry into this workflow is the \lang{} AST (\Cref{subsec:ast}).
Notably, this AST is represented in JSON format, hence serializable, enabling the ability
to be exported/imported from various other environments.
We implement \lang{} as an embedded DSL in JavaScript (JS), 
which constructs the \lang{} AST from \lang{} queries.
Additionally, alternative interfaces can be used, such as pipes (\Cref{subsec:fluent}),
or entirely textual inputs that can be processed by a parser to construct the same AST.
Once the AST is constructed, it gets transformed into \lang{} IR.
During this transformation, declarative query operators are mapped to IR instructions
along with their dependencies.
Subsequently, this IR is used to analyze the looping structure and generate the final
code.

\begin{figure}[t!]
\begin{subfigure}{\textwidth}
\begin{minipage}{0.3\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible]
// input dataset
let data = [
  {key: "A", val: 10},
  {key: "B", val: 15},
  {key: "A", val: 25}
]
// query
sum('data.*.val')
// AST constructed from the query:
{agg: 'sum', param: 'data.*.val'}
// result: 50
\end{lstlisting}
\end{minipage}
\begin{minipage}{0.3\textwidth}
% \centering
\hspace{3.6mm}
\includegraphics[width=0.657\textwidth]{images/intro_q1_ir.pdf}
\end{minipage}
\begin{minipage}{0.38\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible, numbers=left, xleftmargin=2pt]
let tmp = {}
// ??= is assign if null operator
tmp[0] ??= 0
(*@\highlight[highlightblue]{for (let star in data) }@*) {
  tmp[0] += data[star]['val']
}
return tmp[0]
\end{lstlisting}
\end{minipage}
\vspace{-4mm}
\caption{A query computing the sum of all values}\label{fig:intro_q1}
\end{subfigure}

\begin{subfigure}{\textwidth}
\begin{minipage}{0.3\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible]
// query
{
  total: sum('data.*.val'),
  'data.*.key': sum('data.*.val')
}
// AST constructed from the query:
{
  total:
    {agg: 'sum', param: 'data.*.val'},
  'data.*.key':
    {agg: 'sum', param: 'data.*.val'}
}
// result:
//  { total: 50, 
//    'A': 35,
//    'B': 15 }
\end{lstlisting}
\end{minipage}
\begin{minipage}{0.3\textwidth}
% \centering
\hspace{3.6mm}
\includegraphics[width=0.657\textwidth]{images/intro_q2_ir.pdf}
\end{minipage}
\begin{minipage}{0.38\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible, numbers=left, xleftmargin=2pt]
let tmp = {}
tmp[0] ??= {}
tmp[0]['total'] ??= 0

(*@\highlight[highlightblue]{for (let star in data) }@*) {
  tmp[0]['total'] += data[star]['val']
  tmp[0][data[star]['key']] ??= 0
  tmp[0][data[star]['key']] += data[star]['val']
}
return tmp[0]
\end{lstlisting}
\end{minipage}
\vspace{-4mm}
\caption{A query computing sum of all values
(\inline{total}) and sum per each key}\label{fig:intro_q2}
\end{subfigure}

\begin{subfigure}{\textwidth}
\begin{minipage}{0.33\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible]
// query
{
  'data.*A.key': div(sum('data.*A.val'), 
                    sum('data.*B.val')) 
}
// AST constructed from the query:
{
  'data.*.key': {
    path: 'div',
    param: [
      {agg: 'sum', param: 'data.*A.val'},
      {agg: 'sum', param: 'data.*B.val'}
    ]
  }
}

// result:
// {'A': 0.7, 'B': 0.3}
\end{lstlisting}
\end{minipage}
\begin{minipage}{0.27\textwidth}
% \centering
\hspace{1mm}
\includegraphics[width=0.73\textwidth]{images/intro_q3_ir.pdf}
\end{minipage}
\begin{minipage}{0.38\textwidth}
\begin{lstlisting}[style=JavaScriptTiny, columns=flexible, numbers=left, xleftmargin=2pt]
let tmp = {}
tmp[1] ??= {}
tmp[2] ??= 0

(*@\highlight[highlightblue]{for (let starB in data)}@*) {  // loop hoisted!
  tmp[2] += data[starB]['val']
}

tmp[0] ??= {}
(*@\highlight[highlightred]{for (let starA in data)}@*) {
  tmp[1][data[starA]['key']] ??= 0;
  tmp[1][data[starA]['key']] += data[starA]['val']
  tmp[0][data[starA]['key']] = tmp[1][data[starA]['key']] / tmp[2] (*@\label{line:deps}@*)
}
return tmp[0]
\end{lstlisting}
\end{minipage}
\vspace{-2mm}
\caption{A query computing key-specific 
relative aggregate proportions
}\label{fig:intro_q3}
\end{subfigure}
\vspace{-2mm}
\caption{
The end-to-end workflow of \lang{} for three queries, starting with the query
and the corresponding AST (left; \Cref{subsec:ast}),
followed by the construction of the IR (center; \Cref{subsec:ir}), and the final generated code (right).
}\label{fig:intro} 
\vspace{-7mm}
\end{figure}

\Cref{fig:intro} shows this end-to-end workflow using several example queries.
Specifically, the query is shown on the left, alongside its AST representation,
the IR in the center, and the generated code on the right.
While the comprehensive exploration of these components will be the focus of
subsequent sections in this paper, we offer an introductory overview of each
element here.

Consider the query in \Cref{fig:intro_q1}.
In \lang{}, 
\inline{data.*.val} is called a \emph{path} expression, a notation inspired by
JSONPath~\cite{jsonpath}.
The \inline{*} symbol serves as an iterator, facilitating iteration through
the \inline{val} values, while the aggregator \inline{sum} calculates the sum of
these iterated values.
\lang{}'s IR (shown in the center) consists of two main types of operators.
First, it has \emph{generators} (represented as \emph{rounded} rectangles),
which represents iterators
that enumerate a list of items (ultimately translated into loops in
the generated code).
In our example, \inline{data.*} is a generator, iterating values from the data object.
Second, the IR has \emph{assignments} (represented as rectangles), comprising the
computations required for executing the query.
In the case of our first query, the initialization logic \inline{tmp[0] ??= 0} and
the subsequent sum computation \inline{tmp[0] += ...} are assignments.

Notably, the IR operates without the need for explicit control flow constructs.
Instead, the program's structure is implicitly inferred through dependencies.
For our example query, the assignment \inline{tmp[0] += ...} has dependencies to
both the initializer (because initialization must come first) and the generator
(because its operand is the iterated value).
Additionally, it is worth noting that computations are performed on temporary
state variables (\inline{tmp[0]} in the first example).
This approach, utilizing intermediate temporaries, draws inspiration from works
such as RPAI~\cite{rpai} and DBToaster~\cite{dbtoaster_vldb}.
These systems utilize such state variables to maintain values for
various sub-queries of the main query, which are then used to compute the
final result.
Finally, the IR is translated into JS code (and compiled using \inline{eval()}),
taking dependencies into account to extract the program structure and performing
optimizations as part of this transformation process.

\Cref{fig:intro_q2} and \Cref{fig:intro_q3} illustrate two additional queries executed on
the same dataset.
Specifically, in \Cref{fig:intro_q2}, we compute both the total sum of all values
(similar to the query in \Cref{fig:intro_q1}) and the sum of values per key, effectively
a group-by sum operation.
A key characteristic of \lang{} lies in the contextual interpretation of expressions
such as \inline{sum(data.*.val)}.
That is, the semantics of this expression differs depending on its context.
This is similar to local unification semantics in Verse~\cite{verse}.
For instance, when it is nested within \inline{\{data.*.key: ...\}},
the expression signifies a group-by sum operation.
Conversely, if it is not nested within an iterator (i.e., \inline{*}),
it calculates the aggregate over the entire set of values.
This distinction is exemplified in the query presented in \Cref{fig:intro_q3}.
Here, \inline{sum(data.*A.val)} is nested within \inline{\{data.*A.key: ...\}}, signifying a
group-by aggregate operation.
Conversely, \inline{sum(data.*B.val)} computes a total aggregate, as it is not nested
within a \inline{*B} iterator.

Additionally, \Cref{fig:intro_q3} also demonstrates an optimization that occurs at the IR level.
Specifically, even though the \inline{sum(data.*B.val)} appears as a nested sub-query
in the original query, the \lang{} backend can determine that the generated
\inline{*B} can be hoisted out as a separate loop by analyzing the IR dependencies.
This is essentially similar to sub-query hoisting that happens at the logical plan level
in other traditional query optimizers.

These examples provide a broad overview of \lang{}'s functionalities and its
syntactic structure.
In the subsequent sections of this paper, we will delve deeper into the syntax and capabilities
of \lang{} and discuss the process of IR construction and code generation.
Moreover, the previous example queries focused on \lang{}'s capability to
express analytical queries on JSON objects.
However, \lang{} covers an even broader
spectrum of use cases, including the ability to express tensor computations and declaratively specify
visual components (e.g., tables, charts) of web applications.
% For example, this includes its ability to 
% express tensor computations in a style similar to
% Einstein notation as we discuss in \Cref{subsec:tensor}.

Our specific contributions are as follows.
\begin{itemize}
    \item We introduce the syntax of \lang{}, showcasing the ability to express common data
          manipulation operators such as selections, group-bys, joins, user-defined functions (UDFs),
          and others (\Cref{sec:query_language}).
    \item We highlight the versatility of \lang{} across various use cases, including the expression
          of visual elements in web applications (e.g., tables, charts using SVG), declarative
          tensor computations (akin to Einsum), and alternative `pipe' APIs via metaprogramming (\Cref{sec:case_studies}).
    \item We elucidate the process of lowering queries into an IR that features loop-free and
          branch-free code, with dependencies implicitly representing the program structure.
          Then, we illustrate how this IR facilitates code generation by constructing the optimal program
          structure from dependencies (\Cref{sec:ir_codegen}).
    \item We evaluate the performance of \lang{} on several JSON analytics workloads
          to demonstrate the effectiveness of our code generation approach (\Cref{sec:experiments}).
\end{itemize} 

We discuss related work in \Cref{sec:related_work}, followed by conclusions and potential future research directions
in \Cref{sec:conclusions}.


\vspace{-2mm}
\section{The \lang{} Query Language}\label{sec:query_language}
\vspace{-2mm}
In the previous section, we saw \lang{} in action for a set of relatively simple queries.
In this section, we will introduce the syntax of \lang{}, illustrating
how it facilitates the expression of common data manipulation operations like
selections, aggregates, group-bys, and so on.
The formal grammar is shown in \Cref{fig:grammar}.
The rest of this section illustrates how each of these components are used to express
different kinds of queries.
To improve understanding, we will employ a running illustrative example dataset, as
depicted below.
The dataset contains populations of several major cities,
along with the respective country.
Our chosen dataset is deliberately kept simple, devoid of
intricate nested structures.
However, \lang{} has the capacity to seamlessly query
nested JSON data in the same way.
We will see such examples later in \Cref{sec:case_studies}.

\begin{lstlisting}[style=JavaScript]
let data = [
  {country: "Japan",  city: "Tokyo",      population: 14},
  {country: "China",  city: "Beijing",    population: 22},
  {country: "France", city: "Paris",      population: 3},
  {country: "UK",     city: "London",     population: 9},
  {country: "Japan",  city: "Osaka",      population: 3},
  {country: "UK",     city: "Birmingham", population: 2}
]
\end{lstlisting}


\begin{figure}[t!]
\scriptsize
\begin{minipage}{0.5\textwidth}
\begin{align*}
\text{Ident} &::= \texttt{[a-zA-Z\_][a-zA-Z0-9\_]*} \\
\text{Num} &::= \texttt{[0-9]+} \\ 
\text{Var} &::= \texttt{*}\;\text{Ident} \\
\text{ScalarOp} &::= \textsf{get} \mid \textsf{apply} \mid \textsf{plus} \mid \textsf{minus} \\ 
&\mid \textsf{div} \mid \textsf{fdiv} \mid \textsf{times} \mid \textsf{mod} \\ 
\text{ReductionOp} &::= \textsf{sum} \mid \textsf{count} \mid \textsf{max} \mid \textsf{min} \\ 
&\mid \textsf{first} \mid \textsf{last} \mid \textsf{array}
\end{align*}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{align*}
\text{Atom} &::= \text{Ident} \mid \text{Num} \mid \text{Var} \\
\text{Path} &::= \text{Atom ( . Atom )*} \\
\text{Expr} &::= \;\text{Path} \\
&\quad\;\; \mid \text{Expr} \ \text{ScalarOp} \ \text{Expr} \\
&\quad\;\; \mid \text{ReductionOp ( Expr )} \\
&\quad\;\; \mid \text{[ Expr ]} \\
&\quad\;\; \mid \text{\{ ( Path : Expr )* \}} \\
\text{Query} &::= \text{Expr}
\end{align*}
\end{minipage}

% \vspace{-7mm}
\caption{Syntax for expressing \lang{} queries.}\label{fig:grammar}
\vspace{-5mm}
\end{figure}

\vspace{-4mm}
\subsection{Basics}
\vspace{-2mm}
First we will look at how to perform several basic query operations on the
aforementioned dataset.
For instance, if we want to select a particular key of the dataset at a given
index, we can use the following syntax.

\begin{lstlisting}[style=JavaScript]
'data.2.country'              // result: France
{first : 'data.0.country'}    // result: {first: Japan}
\end{lstlisting}

Several key attributes of \lang{} can be observed from the aforementioned examples.
Here, the reference \inline{data} refers to
the dataset object, 
and can be simply indexed through integer indices.
Furthermore, specific keys can be selected by specifying the desired
key names (e.g., \inline{.country}).
Notably, \lang{} offers the convenience of the familiar JS-like syntax for constructing
structured output from extracted values, as exemplified in the second instance.

While this form of explicit indexing into the array can be useful for several
use cases, generally, queries involve some form of iterating over the dataset.
\lang{} offers this capability through the \inline{*} operator,
serving as an implicit iteration operator.
Moreover, as we saw in \Cref{fig:intro_q3}, we can perform controlled iteration with multiple
generator symbols (e.g., \inline{*A}, \inline{*B}, etc.).
In fact, these generator symbols behave like logic variables in Datalog, Prolog,
and other logic programming languages as we see in \Cref{subsec:tensor}.
Below, we present three example queries that leverage iterators and compute
aggregates over the iterated values.

\begin{lstlisting}[style=JavaScript, columns=flexible]
['data.*.city']                  // result: [Tokyo, Beijing, ..., Birmingham]
sum('data.*.population')    // result: 53
max('data.*.population')    // result: 22
\end{lstlisting}

These queries are self-explanatory in nature.
In the first example, we illustrate a scenario where an array can be constructed
from the values obtained through iteration, employing the \inline{[...]} syntax.
Moreover, users can compute aggregates over the iterated values using the
relevant aggregate functions, such as \inline{sum}, \inline{max}, and so forth.
As discussed previously, these queries can be used as parts of object
construction logic and combined flexibly, as shown below.

\hspace{-18pt}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=none]
{ total: sum('data.*.population'), 
  highest: max('data.*.population') }
\end{lstlisting}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=none]
// result: 
//  {total: 53, highest: 22}
\end{lstlisting}
\end{minipage}

\vspace{-3mm}
\subsection{Group By}\label{subsec:groupby}
\vspace{-2mm}
% Up to this point, we have explored fundamental query operations, including indexing,
% iteration, and aggregate computation.
Another vital query operator, especially relevant to JSON-style objects,
is the group-by query.
\lang{} offers an intuitive means of implicitly expressing group-bys.
The following query exemplifies this, grouping records based on the
\inline{country} attribute and subsequently calculating the total population
for each group:

\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=none]
{ 'data.*.country': sum('data.*.population') }
// result: {Japan: 17, China: 22, France: 3, UK: 11}
\end{lstlisting}

Here, specifying \inline{\{data.*.country: ...\}} as the key implies
that any iteration carried out within this key utilizing the same
iterator (\inline{*}) is performed for records with each unique value of \inline{country}
separately.
The next example shows how to use this form of grouping to compute aggregates at different
levels.
It computes the total population of all records, breaks it down by country,
and subsequently computes the population proportion of each city with respect to total
population:

\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=none]
let query = { 
  total: sum('data.*.population'),                                    // total population
  'data.*.country': {
    total: sum('data.*.population'),                                  // population per country
    'data.*.city': div(sum('data.*.population'),                      // population proportion
                          sum('data.*A.population'))}                 // (per each city)
}
// result: {total: 53, Japan: {total: 17, Tokyo: 0.26, Osaka: 0.06}, ...}
\end{lstlisting}

In the given query, the \inline{sum('data.*.population')} at each query level computes
distinct results: total population, total population per country, and population per city,
respectively. 
If we had multiple population values for a given city (e.g., county data), then the
last aggregation would compute the per city sum.
As previously discussed, since \inline{sum('data.*A.population')} is not nested within a
\inline{*A} key, it performs a total aggregation, which sums all the population values.
It is worth noting that our implementation employs calls like \inline{div} for some operators
since it functions as an embedded DSL in JS.
In a textual frontend, the query could appear even more concise, using standard operators 
like \inline{/} for division.

\vspace{-3mm}
\subsection{Join}
\vspace{-2mm}
Joins are another fundamental operator in data querying.
To illustrate how joins work in \lang{}, consider the following
new dataset named \inline{other}, which includes information about the
\inline{region} to which each country belongs:

\begin{lstlisting}[style=JavaScript, columns=flexible]
let other = [
  {country: "Japan",         region: "Asia"},
  {country: "China",         region: "Asia"},
  {country: "France", region: "Europe"},
  {country: "UK",            region: "Europe"},
]
\end{lstlisting}
\vspace{-2mm}

Now, consider a scenario where we aim to compute aggregate population
values based on regions.
For this, we must perform a join between our original
\inline{data} and this new \inline{other} object to acquire the
corresponding region for each country.
The following \lang{} query illustrates how this is expressed.

\begin{lstlisting}[style=JavaScript, columns=flexible]
let countryToRegion = {                                         // create a mapping of 
  'other.*O.country': 'other.*O.region'                         // country -> region
}
let query = {
  '-': keyval(get(countryToRegion, 'data.*.country'), { // Use of "-" and keyval is because
    total: sum('data.*.population')                                       // JS enforces JSON keys to be
      'data.*.country' : sum('data.*.population')                         // strings and our key is a var
    })
}
// result: {Asia: {total:39, Japan:17, China:22}, Europe: {total:14, France:3, UK:11}}
\end{lstlisting}

Here, we use a distinct query (\inline{countryToRegion}) to retrieve the
corresponding region for a given country.
The main query conducts a group-by based on the \inline{region} (retrieved using \inline{get}) 
first, followed by another group-by based on \inline{country}, ultimately computing the
desired aggregates.
We use \inline{'-'} in our implementation due to JS's requirement that JSON
keys be represented as strings.
Consequently, specifying \inline{get(countryToRegion, 'data.*.country')} as the key directly
is not possible.
Hence, we introduce \inline{keyval(<key>, <value>)} as a workaround that allows arbitrary
arguments to be used as a key.
It is worth noting that in a textual frontend, such workarounds would not be necessary.

% As with the example in \Cref{subsec:groupby}, we employ a distinct query
% (\inline{countryToRegion}) to map countries to regions.
% The \inline{keyval(<key>, <value>)} construct is utilized to specify the mapped region
% as the key.
% This query conducts a group-by based on the \inline{region} attribute initially,
% followed by another group-by based on \inline{country}, ultimately calculating the
% desired aggregates.

% \todo{perhaps discuss this in future work}
% \subsection{Conditionals}
% \todo{
%     discuss about expressing filters. Duality with lambdas + if.
% }
% One approach to handle conditionals is to provide 

% \begin{lstlisting}[style=JavaScript, columns=flexible]
% data2Map = {"data2.*.key": sum("data2.*.value")}
% query = {"data.*.key": get(data2Map, "data2.*.value")}

% // RPAI-style maps
% // select sum(r.A*r.B) from R r where 
% // 0.5*(select sum(r1.B) from R r1) == (select sum(r2.B) from R r2 where r2.A = r.A)
% lhsSum = sum(r.*p.B)
% rhsSum = { "r.*q.A": sum("r.*q.B")} // A --> rhsSum

% // TODO: how to express this declaratively?
% ansMap = { ???: sum(times("r.*q.A", "r.*q.B")) } // rhsSum --> sum(A*B)
% // need a way to encode shift of aggregates! 
% query = get(ansMap, lhsSum)
% \end{lstlisting}

\vspace{-3mm}
\subsection{User-defined Functions}
\vspace{-2mm}
\lang{} allows using user-defined functions (UDFs) written in JS seamlessly with the
queries.
Consider a simple query where we want to obtain the percentage population per each
country from our dataset.

\begin{lstlisting}[style=JavaScript, columns=flexible]
let udf = {
  formatPercent: v => (v*100).toFixed(2) + "%" // computes the percentage 
}
let query = {
  'data.*.country':
    apply(udf.formatPercent, div(sum('data.*.population'), sum('data.*A.population')))
}
// result: {Japan: 32.05%, China: 41.50%, France: 5.66%, UK: 20.75%}
\end{lstlisting}

We have defined the UDF \inline{formatPercent} that, given a proportion value,
computes the percentage and adds a \% sign at the end.
We can then use \inline{apply} in the query to call this UDF to convert the
proportions to percentages.


% \subsection{Arrays}
% We have encountered aggregates such as \inline{max}, \inline{min}, and \inline{sum}
% thus far.
% However, there can be scenarios where we require an aggregate that collects values
% into an array.
% For this, we provide the \inline{array} construct, also represented in \inline{[]} syntax.

% \begin{lstlisting}[style=JavaScript, columns=flexible]
% array('data.*.country')                                   // [Japan, China, France, ...]
% [{city: 'data.*.city'}]                                   // [{city: Tokyo}, {city: Beijing}, ...]
% [{country: 'data.*.country'}, {city: 'data.*.city'}]// [{country: Japan}, {city: Tokyo}, ...]
% [{country: 'data.*.country', city: 'data.*.city'}]        // [{country: Japan, city: Tokyo}, ...]
% \end{lstlisting}

% In the examples provided above, we show a set of simple queries that aggregate values
% into arrays.
% Each query is self-explanatory, with the expected result displayed on the right.
% Importantly, similar to other types of \lang{} operations, this array accumulation
% seamlessly integrates with other query constructs.

\vspace{-3mm}
\subsection{\lang{} AST}\label{subsec:ast}
\vspace{-2mm}
As we saw in \Cref{fig:intro_overview,fig:intro}, all the queries
above construct a \lang{} AST representation which serves as the basis
for the dependency analysis and IR construction.
This AST representation is in JSON format, and closely mirrors the query JSON structure.
The difference is, all the calls to reducers like \inline{sum}, \inline{count}, etc.
and other operations like \inline{plus}, \inline{minus}, etc. will be translated to
explicit objects components with \inline{agg} (or \inline{path}) and the corresponding
arguments.
\inline{agg} is for reducers (which are stateful), and \inline{path} is for operations
simply performs a lookup and some computation.
For instance, \Cref{fig:intro_q3} (left) shows how \inline{sum} is translated to \inline{agg}
and \inline{param}, and \inline{div} is translated to \inline{path} and param.

This AST representation serves as the entry point for our compiler backend, and gets
translated into an IR, as elucidated in \Cref{sec:ir_codegen}.
Moreover, as depicted in \Cref{fig:intro_overview}, the creation of this AST is not
limited to the aforementioned JS embedding.
Instead, it can be constructed using different APIs, (e.g., Fluent API introduced in \Cref{subsec:fluent}),
or a textual frontend with a parser, and so on.

\vspace{-4mm}
\section{Case Studies}\label{sec:case_studies}
\vspace{-3mm}
\subsection{Fluent API}\label{subsec:fluent}
\vspace{-2mm}
\lang{}'s query frontend (JSON) we saw in \Cref{sec:query_language} describes the query
using the structure of the computed \emph{result}.
However, sometimes, it is more natural to start from the structure of the 
\emph{input}, and specify a sequence of transformation steps.
Given that our frontend is embedded in JS, we can use metaprogramming to
layer a LINQ-style~\cite{linq_sigmod} pipeline API on top.
% Sometimes, the JSON-style query interface can be cumbersome,
% especially when dealing with deeply nested objects.
% To address this issue, \lang{} offers a higher-level API that employs
% metaprogramming to compose queries more easily.
% This `fluent' API provides a pipeline-oriented interface that
% simplifies complex queries.

To illustrate the advantages of such an interface, consider a
simple task borrowed from Advent of Code 2022~\cite{adventofcode22}.
The task involves processing a sequence of values partitioned into chunks,
each containing multiple values.
The objective is to calculate the sum of values for each chunk and
subsequently identify the maximum sum among those computed.
To begin, let us examine how the \lang{} query appears when utilizing
the familiar JSON-style API for data parsing and computation.
First, we define several user-defined functions (UDFs) to assist with data parsing.
The role of each UDF is simple and self-explanatory.

\begin{lstlisting}[style=JavaScript, columns=flexible]
let input = '100,200,300|400|500,600|700,800,900|1000' // sample input
// some UDFs for parsing the data
let udf = {
  'splitPipe' : x => x.split('|'),
  'splitComma': x => x.split(','),
  'toNum'         : x => Number(x)
}
\end{lstlisting}

Shown below is the \lang{} query responsible for executing the required
computation, with comments provided alongside to elucidate each section
of the query (numbered for clarity):

\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=left]
let query = max(get({                      // 5. find maximum among group sums
  '*chunk': sum(                           // 4. group-by chunk and compute sum
    apply('udf.toNum',                     // 3. convert each string number to a number object
      get(apply('udf.splitComma',          // 2. split by comma to get numbers of each chunk
        get(apply('udf.splitPipe', '.input'), '*chunk')), // 1. split into chunks
        '*line')))
  },'*'))
\end{lstlisting}

Function \inline{apply()} is used to apply UDFs to arguments;
\inline{get()}, when used with an unbounded generator symbol (e.g., \inline{*chunk}), binds the
iterator to the object in the first argument.
For example, in Line 5, \inline{get(..., '*chunk')} binds the iterator
\inline{*chunk} to the result of splitting the output by the pipe symbol (\inline{|}).
While this approach works as intended and yields the correct results, 
for these kinds of workloads, it is more natural to think starting from the input
instead of the output structure.
In such cases, \lang{}'s `fluent' interface offers an alternative way to express
this query concisely as shown below.
Here, we specify the query as a sequence of transformation steps on the input.
This high-level fluent API essentially functions as a metaprogramming layer
that generates an equivalent \lang{} AST as before.

\begin{lstlisting}[style=JavaScript, columns=flexible]
let query =
  pipe('.input')
    .map('udf.splitPipe').get('*chunk')      // 1. split into chunks (and bind to *chunk)
    .map('udf.splitComma').get('*line')      // 2. split by comma to get numbers of each chunk
    .map('udf.toNum')                               // 3. convert each string number to a number object
    .sum().group('*chunk').get('*')                 // 4. group-by chunk and compute sum
    .max()                                          // 5. find maximum among group sums
\end{lstlisting}

The \inline{pipe()} function creates a \inline{Pipe} object equipped with
methods \inline{sum}, \inline{max}, and so on, all of which return a
\inline{Pipe}.
The \inline{map()} function, similar to \inline{apply()} mentioned earlier,
is employed to apply a UDF, and \inline{group()} is used to perform a group-by
(i.e., \inline{e.group(x)} is \inline{\{x : e\}}).

% \todo{show the definition of group?}


% \subsection{GUI Components}
% Basic building blocks -- table definition, and generic display, svg, etc. 

\vspace{-4mm}
\subsection{Tensor Expressions}\label{subsec:tensor}
\vspace{-2mm}
\lang{} provides an elegant framework for expressing tensor computations,
drawing inspiration from the Einstein summation (Einsum) notation frequently
employed in tensor frameworks and Einops~\cite{einops}.
The Einsum notation offers a concise means of articulating tensor computations.
For instance, $ik,kj \rightarrow ij$ specifies a standard matrix
product that takes two two-dimensional tensors (i.e., matrices $A$ and $B$), and yields a third
tensor (say $C$), as the result, computed as $C_{ij} = \sum_k A_{ik} \times B_{kj}$.
Likewise, complex tensor computations involving multiple n-dimensional tensors can
be specified using such declarative expressions.

\lang{} provides a similar way to express tensor computations in a declarative fashion.
To perform tensor computations, we rely on using the notion of unbounded iterators in \lang{}.
Specifically, in prior cases, we explicitly specified the data source from which we iterate,
as seen in constructs like \inline{data.*A}.
However, if instead we only specify the iterator as the key, \lang{}'s backend
automatically determines the appropriate data source by examining the query body.
For instance, when we have a query like \inline{\{*i: sum(times(A.*i, B.*i))\}}, the
backend selects either \inline{A} or \inline{B} as the data source for iteration.
Subsequently, the generated code ensures that the iterated values exist in
both \inline{A} and \inline{B}.
This concept essentially parallels the notion of unification in logic programming,
and more specifically narrowing in functional logic programming\cite{curry,verse}.

To demonstrate how tensor computations are expressed in \lang{}, let's consider
some examples.
While \lang{} accommodates tensors in various nested formats, for the sake of simplicity,
we will consider a scenario where we represent tensors using JS Arrays, as illustrated below:
\begin{lstlisting}[style=JavaScript,columns=flexible]
let A = [[1, 2], [3, 4]]; let B = [[1, 2, 3], [4, 5, 6]]
\end{lstlisting}

Shown below are a set of example tensor computations expressed in \lang{}.
Einsum notation counterparts (which closely mirrors \lang{} query structure) 
are shown in parentheses for each example.

\hspace{-18pt}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[style=JavaScript,columns=flexible]
// tensor transpose (ij->ji)
{'*j': {'*i': 'B.*i.*j'}}
// sum of all elements (ij->)
sum('B.*i.*j')
// column sum (ij->j)
{'*j': sum('B.*i.*j')}
// row sum (ij->i)
{'*i': sum('B.*i.*j')}
// dot product (vector-vector) (i,i->)
sum(times('vecA.*i', 'vecB.*i'))
\end{lstlisting}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[style=JavaScript,columns=flexible]
// matrix multiplication (ik,kj->ij)(*@\label{code:matmulquery}@*)
{'*i': {'*j': sum(
  times('A.*i.*k', 'B.*k.*j')) }}
// Hadamard product (ij,ij->ij)
{'*i': {'*j': times('A.*i.*j', 'B.*i.*j') }}
// general tensor contraction (n-d Tensors)
// e.g., pqrs,tuqvr->pstuv
{'*p':{'*s':{'*t':{'*u':{'*v':sum(
  times('T1.*p.*q.*r.*s', 'T2.*t.*u.*q.*v.*r')) }}}}}
\end{lstlisting}
\end{minipage}

One benefit of having a unified query language for both data manipulation and tensor
computations is the ability to handle combined workloads efficiently.
To illustrate this, consider a simplified version of computing a city's
`crime index' (taken from~\cite{weld}).
We first select a set of features of cities (e.g., population, 
adult population and number of robberies), followed by a dot product
with a predefined weight vector.

\begin{lstlisting}[style=JavaScript,columns=flexible]
let cityVec = { 'data.*.city': ['data.*.pop', 'data.*.adultPop', 'data.*.numRobs'] }
let weightVec = [1.0, 1.0, -2000.0] // weight of each feature
let crimeIndex = {    // dot product
  'data.*.city': sum(times('weightVec.*i', get(get(cityVec, 'data.*.city'), '*i')))
} // computes the crime index for each city
\end{lstlisting}

We can specify both the data manipulation component (i.e., the projection) and
the tensor computation (i.e., dot product) within the same query language, and
we generate a unified code for the combined task.
While we kept the example simple for brevity, this has the potential to optimize practical
intricate workloads that combine data processing with tensor computations.





% Another key benefit of \lang{} is that these queries, for the most part are agnostic
% to the underlying data structure.
% For instance, one could use a JSON to represent a sparse tensor in a format similar to
% coordinate list (COO) format (e.g., this is the format used in \inline{SparseTensor}
% in TensorFlow) and use the same query to perform a matrix multiplication.
% \begin{lstlisting}[style=JavaScript, columns=flexible]
% let sparseA = [{row: 0, col: 1, val: 1}, {row: 1, col: 0, val: 2}] // [[0, 1], [2, 0]]
% let sparseB = [{row: 0, col: 0, val: 2}, {row: 0, col: 1, val: 1}] // [[2, 1], [0, 0]]
% // query TODO!
% {'*i': {'*j': sum(times('sparseA.*i))}}
% \end{lstlisting}

% These queries also go through the same compilation steps as we saw in \Cref{fig:intro}.
% Specifically, these queries get translated into a loop-free, branch-free IR that contains the
% operators corresponding to the tensor expressions that then get translated into
% optimized JS code.

\vspace{-3mm}
\subsection{Declarative Visualizations}\label{subsec:view}
\vspace{-2mm}
Since \lang{} is embedded within JS, we can extend its capabilities by introducing
a means to \emph{declaratively} specify the visual components of websites using a similar
structural approach.
This allows the seamless integration of data querying logic with the corresponding
data visualization logic, such as creating tables.
This is enabled by a special key called \inline{'\$display'}.
To illustrate this, consider the following example query, alongside its corresponding output:

\hspace{-18pt}
\begin{minipage}{0.6\textwidth}
\begin{lstlisting}[style=JavaScript,columns=flexible]
{
  '$display': 'table'           // display data in a table
  rows: [0], cols: [1], // row:data index, col:keys
  data: [
    {region:"Asia",city:"Beijing",
      "population":{'$display':"bar",value:40}},
    {region:"Asia",city:"Tokyo",
      "population":{'$display':"bar",value:70}}
  ]
}
\end{lstlisting}
\end{minipage}%
\begin{minipage}{0.4\textwidth}
\includegraphics[width=0.7\textwidth]{images/small_table.png}
\end{minipage}

The query above produces the visualization shown on the right.
Specifically, it declaratively specifies to display a table that
has \inline{data} as the underlying data.
This data can be some raw JSON or another \lang{} query.
Notice that we can mix, and manipulate these components as valid
values inside \lang{} queries, and compose them as necessary.
For instance, the progress bars are manipulated as values in the query.
These visualizations can take various forms, including standard DOM elements
like \inline{h1}, \inline{p}, or high-level components like
\inline{table}, \inline{bar}, \inline{select}, and more,
as well as SVG objects.

To exemplify the practical utility of this approach, consider a scenario involving
the visualization of data related to mobile phone supplier warehouses.
Imagine the raw data is represented as an array of JSON objects, each featuring attributes
such as warehouse, product, model, and quantity.
Before delving into the main query, shown below is a helper query.
This auxiliary query calculates the sum of quantities, generates a formatted percentage
total, and presents this information as a progress bar displaying the corresponding percentage.

\begin{lstlisting}[style=JavaScript,columns=flexible]
let computeEntry = {
  'Quantity': sum('data.*.quantity'),
  'Percent': apply('udf.formatPercent', div(sum('data.*.quantity'),sum('data.*B.quantity'))),
  'Bar Chart': {
    '$display': 'bar',
    value: apply('udf.percent', div(sum('data.*.quantity'), sum('data.*B.quantity')))
  }
}
\end{lstlisting}

As previously discussed, the semantics of these aggregations varies depending on the
calling context.
For instance, when invoked within the context of \inline{\{'data.*.warehouse': ...\}}, the
aggregates computed on \inline{*} iterators are grouped based on the \inline{warehouse} attribute.
Below, we present a query that leverages the above sub query and visualizes our data in a pivot table.
This query performs aggregations at multiple levels and displays each level of
aggregate in a single table as shown on the right.
Naturally, this repeated structure could be abstracted further into a single
operation such as \inline{rollup('data.*', [model, product, warehouse], computeEntry)}.

\hspace{-18pt}
\begin{minipage}{0.6\textwidth}
\begin{lstlisting}[style=JavaScript,columns=flexible]
let query = {
  '$display': 'table',
  ...
  data: { Total: {                    
    props: computeEntry,        // total aggregate           
    children: {'data.*.warehouse': { 
      props: computeEntry,      // warehouse-level aggr
      children: 'data.*.product': {     
        props: computeEntry,  // product-level aggr
        children: {
          'data.*.model':      // model-level aggr
              computeEntry
        }
  ...
}
\end{lstlisting}
\end{minipage}%
\begin{minipage}{0.4\textwidth}
\centering
\includegraphics[width=\textwidth]{images/big_table.png}
\end{minipage}

We can similarly use \lang{} to visualize data in different types of charts using SVG graphics
(such examples are omitted due to space concerns).
Regarding how this visualizations are handled in the backend, we start by building the necessary helper
functions to create these components (tables, bars, etc.) programmatically.
Then, the backend is augmented to use these functions whenever a \inline{'\$display'}
is encountered.
Our ultimate goal of these kinds of integrations is to enable users
to use \lang{} to build interactive dashboards and CRUD applications 
directly from a single query.

\vspace{-3mm}
\section{IR and Code Generation}\label{sec:ir_codegen}
\vspace{-3mm}
Up to this point, we have provided an introduction to the syntax of
\lang{} and explored its versatility across various domains.
In \Cref{fig:intro_overview} and \Cref{fig:intro}, we gained a preliminary understanding
of how \lang{} queries are transformed into an IR, which subsequently serves
as the basis for generating optimized code.
In this section, we will delve into a detailed discussion of the IR structure
and the code generation process.

\vspace{-4mm}
\subsection{IR Structure}\label{subsec:ir}
As discussed in \Cref{sec:intro} (\Cref{fig:intro}), the IR structure of \lang{} consists of two
primary types of instructions: \emph{generators} and \emph{assignments}.
Generators correspond to iterators responsible for enumerating input or intermediate
nested objects, and these generators are transformed into loops in the generated code.
Assignments, on the other hand, encompass any form of computation that updates or
initializes an intermediate or output state.

\lang{} queries inherently exhibit nested iterating structures that could be simply
translated into a series of nested loop structures in the generated code.
However, performing this transformation naively and enforcing the `program structure'
implied by the user query would lead to missed optimization opportunities like
hoisting computations and loops that are independent of outer loops,
common sub-query/expression elimination, and more.
Therefore, rather than naively transforming queries and directly imposing the program
structure, we extract a set of generators, iterators, and their dependencies during
IR construction.
While the IR does not explicitly capture the program structure, the optimal program
structure can be derived from an analysis of these dependencies.

\vspace{-4mm}
\subsection{Constructing the IR}
The dependency structure is relatively straightforward.
As demonstrated in the generated code snippet in \Cref{fig:intro}, we utilize objects such
as \inline{tmp[0]}, \inline{tmp[1]}, and so on, to maintain intermediate results required
for computing the final query result.
Assignment operators have these temporaries as operands, creating data dependencies in the
process.
Generators can also iterate values from these temporaries, and in such cases, we introduce
similar dependencies for the generators.
Similarly, when a generator symbol is used in an assignment or another generator, a
dependency is added.
To illustrate how dependencies are created, consider the following assignment instruction
extracted from Line~\ref{line:deps} in \Cref{fig:intro_q3}:

\begin{lstlisting}[style=JavaScript, columns=flexible, numbers=left, firstnumber=11]
tmp[0][data[starA]['key']] = tmp[1][data[starA]['key']] / tmp[2]
\end{lstlisting}

This instruction relies on \inline{tmp[0]}, \inline{tmp[1]}, and \inline{tmp[2]} as operands.
As a result, this instruction is associated with the last (write) operations of all three
temporaries as dependencies, as depicted in the IR visualization presented in \Cref{fig:intro_q3}.
Furthermore, since it employs the \inline{*A} iterator, it also exhibits a dependency on the
corresponding generator.

% In our current implementation, we track dependencies at the granularity of temporaries like
% \inline{tmp[0]}, \inline{tmp[1]}, etc.
% Specifically, we assign a write rank for each assignment and enforce the strict ordering of
% write ranks during code generation.
% But we can do this in a granular way --> essentially treating each writeRank as an SSA variable
% and track dependencies at that level
% \todo{should we mention this?}

% \subsection{Constructing the IR}

The final missing piece in our lowering process is determining the appropriate
IR instruction from our query AST.
This is done distinctly for reduction operators (those with a
\inline{key} in the AST) and other operators (those with a \inline{path} in the AST).
For reduction operators, which require the management of state, we introduce stateful
temporary variables indexed by the current grouping path.
In this context, `path' refers to the pertinent `parent' grouping keys within the
query nest.
In contrast, other types of operators are simpler to handle.
We retrieve the operands and subsequently create an instruction that performs the
desired computation.
For example, for \inline{plus}, we retrieve the left and right operands and create
a binary operation utilizing the \inline{+} operator.

\vspace{-2mm}
\subsection{Code Generation}
\vspace{-2mm}
Once the IR is constructed for a query, the next step is to generate the final code
taking into account the instruction dependencies.
Specifically, it entails determining where to insert loops, how to nest loops
within one another, where to place assignment instructions, and so on. 
We will use the query from \Cref{fig:intro_q3} as a running example for this
section.

The first step is computing two auxiliary relations:
\inline{tmpInsideLoop} and \inline{tmpAft- erTmp}.
These relations track which temporaries should be scheduled
inside particular loops and which temporaries should be scheduled after
certain other temporaries.
This can be done by analyzing assignment to assignment dependencies and
generator to assignment dependencies.

The next step involves computing the relation \inline{tmpAfterLoop} based on the two
relations computed above.
Specifically, if we determined that a temp variable \inline{t2} should be scheduled after
another temp variable \inline{t1} (i.e., \inline{tmpAfterTmp[t2][t1]}), which resides inside a loop \inline{l}
(with the condition that \inline{t2} itself is not within loop \inline{l}),
then this implies that \inline{t2} should be scheduled after the loop \inline{l}.
For instance, in our sample query, \inline{tmp[0]} should be scheduled after \inline{*A}.

Subsequently, as the final analysis step before code generation, we determine
\inline{loopAfterLoop} and \inline{loopInsideLoop}.
These essentially help identify how the loops should be scheduled.
In particular, if we ascertain that a given temp \inline{t} should be scheduled
inside both loops \inline{l1} and \inline{l2}, it implies that \inline{l1} and
\inline{l2} should belong to the same loop nest.
Conversely, if we determined that for a particular temp \inline{t},
it resides within loop \inline{l2}, and we also know that \inline{t} should be
scheduled after another loop \inline{l1}, then this indicates that the loop \inline{l2}
should be scheduled after \inline{l1} (provided they are not part of the same loop nest).

Once the analysis steps are completed, we proceed with the code
generation process.
Our approach to code generation draws inspiration from the IR scheduling
algorithm utilized in Lightweight Modular Staging (LMS)~\cite{lms}.
In particular, we schedule generators and assignments in an
`outside-in' fashion, commencing with the outer loops before
progressing to the inner ones.

Since we did not have program control structures enforced from the front end,
this code scheduling mechanism freely schedules assignments and generators
in an optimal manner.
For instance, any generator that does not have dependencies to the `outer query'
would be hoisted and scheduled as a separate query instead of repeating the
computation multiple times inside a nested loop.


% \subsection{Implementation}
% \todo{We implement this in <1000 lines of JavaScript, it can run in the browser, etc.}

% \section{Incremental}
% Incremental queries for JSONs, incremental tensor computations!


% \section{Example: Pivot Table}\label{sec:case_study}
% How to use group bys, partial aggregates, display, svg, etc.

\vspace{-4mm}
\section{Experiments}\label{sec:experiments}
\vspace{-3mm}

% \begin{figure}[t]
% \begin{minipage}{0.4\textwidth}
% \centering
% \includegraphics[width=0.8\textwidth]{images/plot.pdf}
% \end{minipage}
% \begin{minipage}{0.6\textwidth}
% \begin{lstlisting}[style=JavaScriptTiny, columns=flexible]
% // data = [ {key1: "A", key2: "B", val: 10}, ... ]
% Q1 = sum('data.*.val')
% Q2 = {
%   total: sum('data.*.val'), 'data.*.key1': sum('data.*.val')
% }
% Q3 = {
%   total: sum('data.*.val'),
%   'data.*.key1': {
%     total: sum('data.*.val'), 'data.*.key2': sum('data.*.val')
%   }
% }
% \end{lstlisting}
% \end{minipage}
% \caption{Running time (left) for JQ, Rumble, and Rhyme for three different simple queries shown
% on right
% }\label{fig:plot}
% \end{figure}



In this section, we conduct a performance evaluation of our current \lang{}
implementation, comparing it against two established JSON processing
systems: JQ~\cite{jq} and Rumble~\cite{rumble_vldb}, the latter of which
utilizes Spark for distributed processing.
We acknowledge that systems like Rumble are primarily designed for large-scale,
cluster execution and may not exhibit optimal performance in a single-node,
single-threaded context.
Nevertheless, we consider it a valuable baseline for comparison.

\vspace{-4mm}
\subsection{Experimental Setup}
We run three queries on a simple synthetic dataset comprising 1 million records of
JSON objects.
Each object in the dataset contains two string keys, \inline{key1} and \inline{key2}, 
as well as an integer \inline{value}.
The first query calculates the sum of all \inline{value}s, the second query performs
an aggregate sum after grouping by the \inline{key1},
and the third query computes a two-level aggregate using \inline{key1}, then \inline{key2}.

We run all the experiments using a single thread, on a NUMA machine
with 4 sockets, 24 Intel(R) Xeon(R) Platinum 8168 cores
per socket, and 750GB RAM per socket (3 TB total) running Ubuntu
18.04.4 LTS.
We have used JQ v1.6, Rumble v1.21.0, and Node v18.18.0 (for running our JS code).
All experiments are run five times, reporting the mean execution time.

\vspace{-4mm}
\subsection{Results}
\begin{wrapfigure}{l}{0.4\textwidth}
\vspace{-30pt}
\centering
\includegraphics[width=0.4\textwidth,clip,trim={7mm 7mm 17mm 12mm}]{images/plot.pdf}
\caption{Running time (left) for JQ, Rumble, and Rhyme for three different queries}\label{fig:plot}
\vspace{-20pt}
\end{wrapfigure} 
Across the three queries, \lang{} demonstrates the best performance.
This can be attributed to its ability to generate optimized JS code tailored
to a specific query, which significantly reduces overhead compared to the
general execution engines employed by systems like Rumble.
JQ performs the worst, as it lacks any form of
`query planning' and executes queries naively without optimizations
such as loop fusion.



While these results highlight the potential performance gains achievable
through \lang{}'s code generation capabilities, it is important to note
that this benchmark does not provide a comprehensive analysis that contains the
full spectrum of representative cases in JSON analytics.
Such a comprehensive evaluation is deferred to future research.

\vspace{-4mm}
\section{Related Work}\label{sec:related_work}
\vspace{-3mm}
There are several query languages designed for working with semi-structured data like
JSON, each with its own focus and strengths.
JSONiq~\cite{jsoniq,jsoniq_paper} is a notable query language explicitly tailored for
JSON data, borrowing most of its syntax from XQuery~\cite{xquery} (e.g., FLWOR expressions).
Zorba~\cite{zobra} and RumbleDB~\cite{rumble_vldb} are examples of engines that support
JSONiq, with RumbleDB using Spark~\cite{spark} as a backend, leveraging the scalability
of Spark for execution.
AsterixDB, designed for semi-structured data, employs AQL~\cite{aql} and SQL++~\cite{sqlpp}
as its query languages.
GraphQL~\cite{graphql}, on the other hand, is widely used in web application development
for querying data from backend services.
% Generally, resolvers for these queries should be manually implemented in the backend.
% Some systems like Hasura~\cite{hasura} automate the generation of SQL queries from
% GraphQL queries, simplifying query resolution.
Most of these languages are specifically targeted towards large-scale JSON analytics workloads
and are not expressive enough to support cases like the ones
in \Cref{subsec:tensor,subsec:fluent,subsec:view}.
While we take inspiration from these languages for the design of the language,
\lang{} is designed to handle various forms of nested data (e.g., tensors),
and it offers support for efficient code generation and optimizations
through its IR.

\lang{}'s path expressions are inspired by JSONPath~\cite{jsonpath} (a descendent of XPath).
Although not discussed extensively in this paper, it is possible to extend \lang{} to support
the full set of JSONPath operators, which include conditions, recursion, etc.
\lang{} also borrows many ideas from functional logic programming languages like
Verse~\cite{verse}, Curry~\cite{curry}, miniKanren~\cite{miniKanren_thesis} and 
Scalogno~\cite{scalango}, and adapts them into a new data-centric declarative language.

% We take inspiration from many other declarative programming languages.
% Specifically, the \lang
% Logic programming, particularly, Datalog - choice and unification, einsum notation - for expressing tensor computations,
% implicit aggregation.

% Recent works like 

% Our generated code

\vspace{-5mm}
\section{Conclusions and Future Work}\label{sec:conclusions}
\vspace{-3mm}
In this paper, we introduced \lang{}, a new query language tailored for high-level
data manipulation.
We illustrated how \lang{}'s design facilitates query optimization and code generation
through the construction of an IR.
This IR comprises loop-free branch-free code, with program structure implicitly captured
by dependencies.
Throughout the paper, we demonstrated the versatility of \lang{} by showcasing its
applicability in expressive data manipulations,
tensor computations, manipulation of visual aspects, and so on in a declarative manner.
It is worth noting that \lang{} is still in its early developmental stages,
and we are excited about exploring various avenues of interesting future work.

\textbf{Incrementality}
While not extensively covered in this paper, the concept of utilizing
intermediate temporaries within the generated code is inspired by prior
works in incremental execution, such as DBToaster~\cite{dbtoaster_vldb}
and RPAI~\cite{rpai}.
An immediate focus of our future work involves introducing support for
incremental execution.
Notably, our generated code is inherently designed to be `incremental-friendly'.
This implies that we have the capability to generate code akin to update
triggers, which are invoked whenever a modification is made to the dataset.
Specifically, instead of dense loops used in the current version, update triggers
generate `sparse' loops in the sense that they iterate only over the deltas.

Another dimension of incrementality involves managing query changes.
This entails finding ways to accommodate changes in queries while maximizing
the utilization of previously computed temporaries and sharing state across
multiple queries. 
Such an approach will be useful in interactive applications, where users
can dynamically modify their queries.

\textbf{Performance}
While the ability to generate JS for browser-based execution is undeniably valuable,
there are specific scenarios where optimizing performance becomes paramount.
In such cases, the generation of low-level, specialized C code becomes imperative to
eliminate any potential overhead associated with managed runtimes.
A substantial body of prior research has already demonstrated the efficacy of
such compilation mechanisms~\cite{500lines,lb2,flare_osdi,sai_guannan}.
Furthermore, it is feasible to leverage existing compiler infrastructures such
as LMS~\cite{lms} or MLIR~\cite{mlir} for streamlined handling of tasks like
IR construction, dependency analysis, and the eventual generation of highly
specialized low-level code.

% \todo{conditionals?}

% \textbf{Missing Operators}
% Currently \lang{} lacks several operators like sorting and conditionals.


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.

\bibliographystyle{splncs04}
\bibliography{references}

% \appendix
% \section{More Declarative Visualizations}\label{apen:moreview}
% Due to space limitations, we decided to move several examples from \Cref{subsec:view}
% involving using \lang{} to declaratively express visualizations
% to the appendix.
% \Cref{subsec:view} illustrated the use of \inline{'\$display'} to create pivot
% tables from some sample data.
% In this section, we will look into the expressivity of \lang{}'s display logic
% for even more type of visualizations.

% Consider a situation where we want to visualize our data in a graph.

\end{document}
